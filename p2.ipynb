{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект 2 &mdash; Построение вопросно-ответной системы\n",
    "\n",
    "## Царькова Анастасия, Скоробогатов Денис, Анвардинов Шариф\n",
    "\n",
    "Необходимые библиотеки: gensim, pymorphy2, pandas, scikit-learn, torch, regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Поиск по документам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С русскоязычной документацией есть проблема, которая заключается в том, что по ней сложно найти вопросов. Можно, конечно, заплатить толокерам, но можно выбрать что-нибудь более популярное. Например, Википедию.\n",
    "\n",
    "Для ответов на вопросы соберем порядка ~100к статей. У Wikimedia Foundation [есть дампы](https://dumps.wikimedia.org/), упорядоченные по времени создания; будем считать, что это примерно эквивалентно значимости тем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  334M  100  334M    0     0  1973k      0  0:02:53  0:02:53 --:--:-- 2015k\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://dumps.wikimedia.org/ruwiki/20171201/ruwiki-20171201-pages-articles1.xml-p4p311181.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В gensim имеется скрипт, который преобразует статьи Википедии из XML в более удобный JSON-формат со схемой `[{\"title\": str, \"section_titles\": [str], \"section_texts\": [str]}]`, попутно разбивая по секциям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-20 17:21:34,470 : MainProcess : INFO : running /place/home/pyos/virtualenv/lib/python3.6/site-packages/gensim/scripts/segment_wiki.py -f ruwiki-20171201-pages-articles1.xml-p4p311181.bz2\n",
      "2017-12-20 17:25:18,170 : MainProcess : INFO : finished running /place/home/pyos/virtualenv/lib/python3.6/site-packages/gensim/scripts/segment_wiki.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.segment_wiki -f ruwiki-20171201-pages-articles1.xml-p4p311181.bz2 > wiki.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем выделять точный ответ, нужно найти небольшое подмножество документов, в котором он будет находиться. Для этого над списком статей поднимем простейший поисковый движок, использующий только три признака: BM25, важность статьи (которую мы приняли убывающей с ее номером) и пересечение запроса и заголовка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9G\twiki.json\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs wiki.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоть задание и выполняется на сервере с 92 ГБ памяти, чтобы его можно было как-нибудь запустить где-то еще документы лучше читать с диска. Для этого нужен маппинг смещений документов в файле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = []\n",
    "with open('wiki.json') as fd:\n",
    "    c = 0\n",
    "    for line in fd:\n",
    "        offsets.append(c)\n",
    "        c += len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97913\n"
     ]
    }
   ],
   "source": [
    "print(len(offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_document(i):\n",
    "    with open('wiki.json') as fd:\n",
    "        fd.seek(offsets[i])\n",
    "        return json.loads(fd.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Соционика'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_document(5)[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim вырезает не всю разметку, поэтому заранее подготовим пару функций для нормализации и токенизации статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return re.sub(r'[\\W\\d_]', ' ', text.replace('\\u0301', '')).lower().split()\n",
    "\n",
    "def strip_markup(text):\n",
    "    return re.sub(r\"['\\[\\]\\*]|[^\\S\\n]\", ' ', text.replace('\\u0301', '')).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно построить лемматизированный инвертированный индекс (`лемма => [(BM25 TF, документ)]`). 40 наиболее часто встречающихся слов будем считать стоп-словами и удалим из индекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import heapq\n",
    "import pymorphy2\n",
    "import collections\n",
    "import multiprocessing\n",
    "\n",
    "def make_index_part(range):\n",
    "    assert range.step is None or range.step == 1\n",
    "    index = {}\n",
    "    doclens = []\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    with open('wiki.json') as fd:\n",
    "        fd.seek(offsets[range.start])\n",
    "        for line, i in zip(fd, range):\n",
    "            a = json.loads(line)\n",
    "            ws = tokenize(a[\"title\"] + \"\\n\\n\" + \"\\n\\n\".join(a[\"section_texts\"]))\n",
    "            ws = collections.Counter(m[0].normal_form for w in ws for m in (morph.parse(w),) if m)\n",
    "            n = sum(ws.values())\n",
    "            for w, c in ws.items():\n",
    "                index.setdefault(w, []).append((c, i))\n",
    "            doclens.append(n)\n",
    "    return index, doclens\n",
    "\n",
    "def merge_index_parts(parts, k1=2, b=0.75):\n",
    "    index = {}\n",
    "    doclens = []\n",
    "    for part, pdoclens in parts:\n",
    "        for word, documents in part.items():\n",
    "            index.setdefault(word, []).extend(documents)\n",
    "        doclens.extend(pdoclens)\n",
    "    avglen = sum(doclens) / len(doclens)\n",
    "    for k, ds in index.items():\n",
    "        ds[:] = [(tf * (k1 + 1) / (tf + k1 * (1 - b + b * doclens[docid] / avglen)), docid) for tf, docid in ds]\n",
    "        ds.sort(reverse=True)\n",
    "    for k in heapq.nlargest(40, index, key=lambda k: len(index[k])):\n",
    "        del index[k]\n",
    "    return index\n",
    "\n",
    "def make_index(processes):\n",
    "    n = len(offsets)\n",
    "    k = int(n ** 0.5)\n",
    "    ranges = [range(i, i + k) for i in range(0, n, k)]\n",
    "    ranges.append(range(n - (n % k), n))\n",
    "    pool = multiprocessing.Pool(processes=processes)\n",
    "    try:\n",
    "        return merge_index_parts(pool.imap(make_index_part, ranges))\n",
    "    finally:\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:1em;background-color:#fff3dd\">_CREATE_INDEX = False если не хочется терять полчаса. Файл с индексом: <a href=\"https://drive.google.com/open?id=1mnap90yWLdw1w1zcXDF7FkkmsYQ4PgGn\">wiki.index</a> (569 MB)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CREATE_INDEX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms in index: 1116242\n",
      "CPU times: user 7min 51s, sys: 15.1 s, total: 8min 6s\n",
      "Wall time: 39min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "if _CREATE_INDEX:\n",
    "    index = make_index(48)\n",
    "    with open('wiki.index', 'wb') as fd:\n",
    "        pickle.dump(index, fd)\n",
    "else:\n",
    "    with open('wiki.index', 'rb') as fd:\n",
    "        index = pickle.load(fd)\n",
    "\n",
    "print('Terms in index:', len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно функция поиска будет просто выбирать документы с максимальным BM25 с двумя нормировочными коэффициентами чтобы учесть важность статей и их заголовки. Поскольку прочитать заголовок статьи довольно медленно, точная релевантность будет считаться только для топ 10n документов по приближенной (без учета заголовка)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def title_boost(docs, terms, norm_terms):\n",
    "    for relevance, docid in docs:\n",
    "        otitle = read_document(docid)['title']\n",
    "        title = tokenize(otitle) or ['']\n",
    "        c1 = sum(w in terms or w in norm_terms for w in title) / len(title)\n",
    "        c2 = sum(w in title or q in title for w, q in zip(terms, norm_terms)) / len(terms)\n",
    "        yield relevance * (1 + c1 * c2), docid, otitle\n",
    "\n",
    "def search(n, terms, k1=2, b=0.75):\n",
    "    docs = {}\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    norm_terms = [m[0].normal_form for t in terms for m in (morph.parse(t),) if m]\n",
    "    for term in norm_terms:\n",
    "        matched = index.get(term, [])\n",
    "        if matched:\n",
    "            idf = math.log(len(offsets)) - math.log(len(matched))\n",
    "        for tf, docid in matched:\n",
    "            docs[docid] = docs.get(docid, 0) + tf * idf / (docid / len(offsets) + 1)\n",
    "    return heapq.nlargest(n, title_boost(heapq.nlargest(n * 10, ((v, k) for k, v in docs.items())), terms, norm_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42.032896488939386, 4058, 'Шонин, Георгий Степанович'),\n",
       " (13.660760083490523, 25435, 'Первый отряд космонавтов СССР'),\n",
       " (10.610559852846151, 2564, '3 августа'),\n",
       " (9.09192417019814,\n",
       "  13030,\n",
       "  'Хронология пилотируемых космических полётов (1960-е)'),\n",
       " (9.086425316549203, 26161, 'Георгий'),\n",
       " (8.607579266306844, 3588, 'Гречко, Георгий Михайлович'),\n",
       " (8.510484015782772, 21819, 'Георгий Александрович'),\n",
       " (8.444983433795262, 11611, 'Гонгадзе, Георгий Русланович'),\n",
       " (8.30055957103546, 2489, '7 апреля'),\n",
       " (8.235992150989222, 97763, 'Мартынов, Георгий Сергеевич')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(10, ['шонин', 'георгий'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.8192173664222704, 1, 'Россия'),\n",
       " (5.0439376004904162, 6874, 'Единая Россия'),\n",
       " (4.9291830861535288, 6655, 'Россия (фракция)'),\n",
       " (4.7466299055857846, 7726, 'ОМОН (Россия)'),\n",
       " (4.304848966103771, 12067, 'Отечество — Вся Россия'),\n",
       " (4.2628455761938611, 7365, 'Россия и Европейский союз'),\n",
       " (4.1404960573959393, 6653, 'Родина (партия, Россия)'),\n",
       " (4.1218742126260075, 16110, 'Живописная Россия (журнал)'),\n",
       " (3.8901328548299361, 6601, 'Наш дом — Россия (фракция)'),\n",
       " (3.5438126941157417, 340, 'День Конституции Российской Федерации')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(10, ['россия'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21.667616662416695, 0, 'Литва'),\n",
       " (18.106700652127323, 16662, 'Президенты Литвы'),\n",
       " (16.115054462630866, 17660, 'Конституция Литвы'),\n",
       " (16.036375557681566, 17543, 'Президент Литовской Республики'),\n",
       " (15.117201428898323, 18971, 'Флаг Литвы'),\n",
       " (13.977364783870822, 17472, 'Бразаускас, Альгирдас Миколас'),\n",
       " (13.965689123542816, 18535, 'Паулаускас, Артурас'),\n",
       " (13.924998164732902, 18424, 'Паксас, Роландас'),\n",
       " (13.85146332590978, 17722, 'Сметона, Антанас'),\n",
       " (13.053533356185294, 22463, 'Срединная Литва')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(10, ['президент', 'литвы'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27.342255365209677, 42791, 'Корпорация монстров'),\n",
       " (14.269100819919847, 38486, 'Взвод монстров'),\n",
       " (13.439909988447205, 37771, 'Страшила (значения)'),\n",
       " (13.277872259581677, 97813, 'Doom 3: Resurrection of Evil'),\n",
       " (13.242000292664974, 40258, 'Монстр в коробке'),\n",
       " (12.978020438827361, 44569, 'Pixar'),\n",
       " (12.570208749196071, 18511, 'Корпорация'),\n",
       " (12.479924957909009, 17274, 'Наблюдатель'),\n",
       " (12.273718471169822, 38651, 'Молодой Франкенштейн'),\n",
       " (11.977213908102271, 17396, 'Фильм ужасов')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(10, ['режиссер', 'корпорации', 'монстров'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22.776387011050335, 478, 'Марс'),\n",
       " (16.132226862021639, 556, 'Марс (значения)'),\n",
       " (16.055522207850881, 17820, 'Фобос'),\n",
       " (15.310275302363497, 29258, 'Маринер (космическая программа)'),\n",
       " (15.225510195386638, 17821, 'Деймос'),\n",
       " (14.859669632564481, 5270, 'Марс (мифология)'),\n",
       " (14.736046047194399, 389, 'XXI век'),\n",
       " (14.251467988783217, 2023, 'Солнечная система'),\n",
       " (14.168303607938626, 29586, 'Марс-экспресс'),\n",
       " (14.165355636124339, 4531, 'Астрономическая единица')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(10, ['расстояние', 'до', 'марса'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, документы более-менее релевантные: топ &mdash; статьи о нужных нам объектах или людях, а дальше несколько связанных (и немного несвязанных) статей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Поиск в параграфе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:1em;background-color:#fff3dd\">Модель обучается <em>очень</em> долго. Результат: <a href=\"https://drive.google.com/open?id=1sI3ch3itKzwicwhP2Ydp0E5YzT5oIjEV\">20171217-172fc9a0.mdl</a> (68 MB) надо поместить в поддиректорию models.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для второй части вопросно-ответной системы обучим на скачанном датасете Сбербанка модуль reader из модели [Facebook DrQA](https://github.com/facebookresearch/DrQA). Для модели нужен word2vec из проекта [RusVectores](http://rusvectores.org/ru/models/) DrQA принимает вектора в текстовом виде, так что конвертируем их gensim-ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  421M  100  421M    0     0  7276k      0  0:00:59  0:00:59 --:--:-- 7315k\n"
     ]
    }
   ],
   "source": [
    "!curl -LO http://rusvectores.org/static/models/ruwikiruscorpora_0_300_20.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors\n",
    "\n",
    "w2v = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\"ruwikiruscorpora_0_300_20.bin.gz\", binary=True)\n",
    "with open(\"data/embeddings/ruwiki_300.txt\", \"w\") as outfile:\n",
    "    for word in w2v.vocab:\n",
    "        vec = w2v[word]\n",
    "        word = word.replace(\"::\", \"_\")\n",
    "        word = word.split(\"_\")[0]\n",
    "        print(word, *vec, file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающая выборка для выделяющей ответы в параграфах модели: ~50к троек (параграф, вопрос, ответ) из задания B соревнования [Сбербанка Data Science Journey 2017](https://sdsj.ru/ru/). Вопросы и ответы придуманы пользователями на Толоке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 74.9M  100 74.9M    0     0  20.9M      0  0:00:03  0:00:03 --:--:-- 20.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://sdsj.ru/train_task_b.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~10000 векторов отделим в валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn.utils\n",
    "\n",
    "data = sklearn.utils.shuffle(pandas.read_csv('train_task_b.csv'), random_state=42)[['paragraph_id', 'question_id', 'paragraph', 'question', 'answer']]\n",
    "data.iloc[:10000].to_csv(\"data/datasets/validate.csv\", header=True, index=False)\n",
    "data.iloc[10000:].to_csv(\"data/datasets/train.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные надо преобразовать из CSV в формат DrQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found few errors with this Tokenizer: 5\n",
      "Total time: 120.5091 (s)\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=.:$PYTHONPATH python scripts/reader/preprocess.py --tokenizer SimpleTokenizer data/datasets/train.csv data/datasets/train-drqa.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found few errors with this Tokenizer: 0\n",
      "Total time: 43.0068 (s)\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=.:$PYTHONPATH python scripts/reader/preprocess.py --tokenizer SimpleTokenizer data/datasets/validate.csv data/datasets/validate-drqa.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, можно обучить модель (название при этом генерируется случайное):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PYTHONPATH=.:$PYHONPATH python scripts/reader/train.py --checkpoint True --train-file train-drqa.json --dev-file validate-drqa.json --embedding-file ruwiki_300.txt --use-lemma True --official-eval False --batch-size 60 --expand-dictionary False --uncased-doc True --uncased-question True --restrict-vocab True --valid-metric exact_match --doc-layers 2 --question-layers 2 --hidden-size 32 >out.log 2>err.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drqa.reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(concat_rnn_layers=True, doc_layers=3, dropout_emb=0.4, dropout_rnn=0.4, dropout_rnn_output=True, embedding_dim=300, fix_embeddings=True, grad_clipping=10, hidden_size=128, learning_rate=0.1, max_len=15, model_type='rnn', momentum=0, num_features=4, optimizer='adamax', question_layers=3, question_merge='self_attn', rnn_padding=False, rnn_type='lstm', tune_partial=0, use_in_question=True, use_lemma=True, use_ner=False, use_pos=False, use_qemb=True, use_tf=True, vocab_size=44249, weight_decay=0)\n"
     ]
    }
   ],
   "source": [
    "predictor = drqa.reader.Predictor('models/20171217-172fc9a0.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем искать ответ в каждом параграфе релевантных статей, считая что отрывки из более релевантных статей с большей вероятностью отвечают на вопрос. Для поискового запроса возьмем сам вопрос без вопросных маркеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(question, stopwords={'кто', 'где', 'когда', 'зачем', 'почему', 'сколько', 'каково'}, top_n=3):\n",
    "    terms = [t for t in tokenize(question) if t not in stopwords]\n",
    "    answers = []\n",
    "    for relevance, docid, title in search(10, terms):\n",
    "        for section in read_document(docid)['section_texts']:\n",
    "            for paragraph in section.split('\\n\\n'):\n",
    "                paragraph = strip_markup(paragraph)\n",
    "                if len(paragraph.split()) > 10:\n",
    "                    for answer, score in predictor.predict(paragraph, question, top_n=top_n * 5):\n",
    "                        answers.append((score * relevance ** 0.5, answer, paragraph))\n",
    "    answers.sort(reverse=True)\n",
    "    return answers[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 21s, sys: 1.75 s, total: 12min 22s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3.0233459882036513,\n",
       "  'в спальном районе Брюсселя.',\n",
       "  'Биография А.А.Пушкина.\\n  \\n   Пушкин и Армия России.\\n   Последний Пушкин живет в спальном районе Брюсселя.'),\n",
       " (2.1925385083262925,\n",
       "  'в июне 1825 года,',\n",
       "  'Следующая встреча Анны Керн с Пушкиным случилась в июне 1825 года, когда она приехала в Тригорское.\\nИменно там Пушкин написал Керн знаменитое стихотворение-мадригал \"К   \"(«Я помню чудное мгновенье…»). В то же время, Анна увлеклась приятелем поэта (и сыном Осиповой, своим двоюродным братом) Алексеем Вульфом.\\nВпрочем, кокетничала она и с соседом Вульфов — помещиком Рокотовым.'),\n",
       " (1.9553251271624139,\n",
       "  '7 января 1833 года Пушкин',\n",
       "  '7 января 1833 года Пушкин был избран членом Российской академии одновременно с П. А. Катениным, М. Н. Загоскиным, Д. И. Языковым и А. И. Маловым.')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "answer('Где жил Пушкин?', top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 32s, sys: 2.26 s, total: 15min 34s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.4381311220828197,\n",
       "  'в начале XVIII века,',\n",
       "  '=== Печать ===\\nПервые периодические издания появились в России в начале XVIII века, однако широкое развитие печатные средства массовой информации получили только в конце XIX века. При этом, если для конца XIX — начала XX века была характерна относительная свобода печати, то для периода СССР — более жёсткая политическая цензура и более высокая степень государственного контроля над печатью. Радикальные подвижки в плане обеспечения свободы печати произошли в ходе демократических реформ конца 1980-х годов. В этот период имел место существенный рост количества периодических изданий, достаточно чётко обозначилась принадлежность тех или иных газет и журналов к различным политическим и общественным течениям.'),\n",
       " (1.9513096059890718,\n",
       "  'Номинальная средняя зарплата работника в',\n",
       "  'Номинальная средняя зарплата работника в России по итогам января 2016 года составила 32 122 рубля в месяц.'),\n",
       " (1.8873475109863831,\n",
       "  'Динамика индекса восприятия коррупции в',\n",
       "  'Динамика индекса восприятия коррупции в России в 1996—2010 годах\\nОценки текущего уровня коррупции в России разнятся. Институт Гэллапа в 2006 году отмечал, что наряду с Камеруном, Украиной, Румынией и Марокко Россия является одним из самых коррумпированных государств в мире (самым коррумпированным признана Литва). Президент фонда ИНДЕМ Г. А. Сатаров критически воспринял оценку Гэллапа («Это исследование оценочное и отражает прежде всего восприятие коррупции людьми, а не столько само явление, что делает индекс не вполне адекватным. При этом в странах с низким уровнем политических свобод люди могут просто бояться давать честные ответы»), хотя и выразил согласие относительно уровня коррупции в России, оценив чистый годовой доход в 2005 году всех российских взяточников «минимум 300 млрд долл». По данным 2011 году, на 143 месте из 182, в списке Transparency International. Однако, согласно исследованию британской аудиторской компании Ernst & Young, проведённому весной 2012 года, за 2011 год коррупционные риски в России значительно снизились и по многим параметрам стали ниже среднемирового уровня. В исследовании Ernst & Young приняли участие свыше 1500 топ-менеджеров крупнейших компаний из 43 стран мира. Так, если в 2011 году 39 % опрошенных в России менеджеров заявляли о необходимости давать взятки наличными для защиты бизнеса или достижения корпоративных выгод, то в 2012 году таких стало 16 %. В 2013 году Россия заняла 127-е место, набрав 28 баллов, столько же сколько и в прошлом году. Только за счёт ухудшения результатов ряда других государств в общемировом списке Россия поднялась на шесть позиций. В 2014 году в Индексе восприятия коррупции Transparency International Россия опустилась на 136 место, набрав 27 баллов. Глава банка ВТБ 24 Михаил Задорнов заявил, что, по его мнению, уровень коррупции в России в настоящее время выше, чем в 1990-х годах. По оценкам международной организации сертифицированных бухгалтеров ACCA, Россия находится в пятёрке стран с наиболее высоким уровнем теневой экономики.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "answer('Когда была основана Россия?', top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min, sys: 780 ms, total: 5min 1s\n",
      "Wall time: 24.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3.4636813966416691,\n",
       "  '25 октября 1992 года.',\n",
       "  'Действующая в настоящее время Конституция Литовской Республики была принята всенародным референдумом 25 октября 1992 года.'),\n",
       " (3.2983522113980444,\n",
       "  'В XVI—XVIII веках в',\n",
       "  'В XVI—XVIII веках в Литве по польскому образцу сложилась политическая система, известная как шляхетская демократия. Она характеризовалась наличием широких прав шляхты (дворянства) в управлении государством. Одновременно с этим происходила полонизация шляхты, выраженная в перенимании правящим сословием Великого княжества Литовского польского языка, культуры и идентичности. На непривилегированные сословия полонизация столь значительного влияния не оказала.'),\n",
       " (3.2765870438033429,\n",
       "  'В июне 2008 года парламент',\n",
       "  '=== Внутренняя политика ===\\nВ июне 2008 года парламент Литвы принял закон, уравнивающий нацистскую и советскую символику и запрещающий её использование в публичных местах: она «  может восприниматься как пропаганда нацистских и коммунистических оккупационных режимов  ». Запрещено «  демонстрирование флагов и гербов, знаков и униформ нацистской Германии, СССР, Литовской ССР, а также флагов, знамён, гербов, знаков, униформ, составными частями которых являются флаги, гербы нацистской Германии, СССР и Литовской ССР  ». Запрещено использование «нацистской свастики, советского серпа и молота, советской пятиконечной красной звезды, а также исполнение гимнов нацистской Германии, СССР и Литовской ССР».')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "answer('Кто президент Литвы?', top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 1s, sys: 688 ms, total: 5min 2s\n",
      "Wall time: 24.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.136749748685336,\n",
       "  'Фредди Крюгер\\n Маньяк',\n",
       "  'Фредди Крюгер\\n Маньяк из серии фильмов «Кошмар на улице Вязов», которого сожгли при жизни и который стал приходить к детям во снах. Смерть во сне вела за собой смерть в реальности.'),\n",
       " (2.0488214819676305,\n",
       "  'Джон Крамер\\nМаньяк',\n",
       "  'Джон Крамер\\nМаньяк из серии «Пила», имеет прозвище «конструктор», он одержим идеей научить людей ценить жизнь, сам лично он своих жертв не убивает, а подстраивает так, чтобы жертвы сами себя убивали.'),\n",
       " (1.9233563672181768,\n",
       "  'Альфред Хичкок,',\n",
       "  'Альфред Хичкок, большинство работ которого больше относятся к триллерам, чем собственно к фильмами ужасов, снимает в этот период знаковый для жанра фильм «Психо», в котором сюжет сосредоточен на маньяке-убийце, а не на его жертвах и попытках поймать преступника, а сам фильм развивает тему психологических триллеров о «женщинах в опасности».')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "answer('Кто режиссер \"Корпорации Монстров\"?', top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..?????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 492 ms, total: 2min 48s\n",
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3.3097845227422815,\n",
       "  '75 часов.',\n",
       "  '3 февраля 1966 года впервые в истории освоения космоса совершила мягкую посадку на поверхность Луны и впервые передала на Землю телепанорамы лунной поверхности. Продолжительность активного существования автоматической лунной станции (АЛС) на поверхности Луны составила 75 часов.'),\n",
       " (3.3023328046779503,\n",
       "  '6200 км от',\n",
       "  'Файл:Luna3-rus.svg|thumb|left|400px|Траектория «Луны-3» и гравитационный манёвр\\nПосле старта с космодрома Байконур космический аппарат «Луна-3» вышел на сильно вытянутую эллиптическую орбиту искусственного спутника Земли с наклонением 75° и периодом обращения 22 300 мин и обогнул обратную сторону Луны по направлению с юга на север, пройдя на расстоянии 6200 км от её поверхности. Под действием гравитации Луны орбита аппарата изменилась; кроме того, поскольку Луна продолжала двигаться по своей орбите, изменилась и плоскость орбиты космического аппарата. Изменение орбиты было рассчитано так, чтобы аппарат при возвращении к Земле снова пролетел над Северным полушарием, где были расположены советские наблюдательные станции. Траектория полёта была рассчитана под руководством М. В. Келдыша в Математическом институте им. В. А. Стеклова.'),\n",
       " (3.1429659934953005,\n",
       "  '45 м.',\n",
       "  'Свою первую обсерваторию Гевелий построил в 1641 году на средства, унаследованные от отца. Телескопы-рефракторы того времени имели серьёзный недостаток — хроматическую аберрацию. Чтобы избавиться от неё, Гевелий строил телескопы огромных размеров, самый большой из них имел 45 метров в длину. Это был «воздушный телескоп» без трубы и без жёсткой связи объектива и окуляра. Телескоп подвешивался на столбе при помощи системы канатов и блоков. Для управления такими телескопами использовались специальные команды из отставных матросов, знакомых с обслуживанием такелажа.\\nТелескоп Гевелия с фокусным расстоянием объектива 45 м.')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "answer('Каково расстояние до Луны?', top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, Пушкин жил в спальном районе Брюсселя, Россия была основана в начале 18 века, режиссером \"Корпорации Монстров\" был Фредди Крюгер, а до Луны 75 часов. Отличная система. От того что ожидалось."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
